{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#theano imports\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "floatX = theano.config.floatX\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The library\n",
    "\n",
    "In this seminar we shall use [AgentNet](https://github.com/BladeCarrier/AgentNet/) library.\n",
    "Agentnet, in essence, is an additional kit of lasagne layers that allow you to build custom recurrent layers.\n",
    "Assuming you already have Bleeding Edge theano and lasagne, you can install it via\n",
    "```\n",
    "git clone https://github.com/yandexdataschool/AgentNet\n",
    "cd AgentNet\n",
    "python setup.py install\n",
    "```\n",
    "in whatever python, environment or container you exist. Alternatively, see docker install instructions in the [readme](https://github.com/yandexdataschool/AgentNet/blob/master/README.md).\n",
    "\n",
    "\n",
    "Depending what python version do you use, in may be \n",
    "* `python3 setup.py install` \\ `python2 setup.py install` if you are using a different python\n",
    "* add sudo - `sudo python setup.py install` - if you have a superuser-installed python\n",
    "* in case you have any problems - contact us or consider using a docker container (see above).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A friendly warning\n",
    "\n",
    "The problem we tackle here is of a relatively small scale, and so are the networks.\n",
    "You can, of course, use GPU, but it is likely to consume more of your time when compiling (seriously, up to some 20-30 minutes), than what it saves during execution.\n",
    "\n",
    "Consider switching to CPU and/or disabling optimization (theano.config.optimizer='None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack-augmented RNN\n",
    "![caption](https://usercontent1.hubstatic.com/6172838_f260.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's menu\n",
    "\n",
    "__The problem__ - train NN to generate sequences of `|`$ a^n b^m c^{n+m} $\n",
    " * n and m are positive integers picked randomly\n",
    " * What do we want exactly:\n",
    "  * Sequence must have a correct form - `|`, some __a__'s, some __b__'s, than some __c__'s and `|` again\n",
    "     * ||aaacbbcba would be a counterexample\n",
    "  * A number of C letters must be as close as possible to the number of A and B letters together\n",
    "     * Ideally, we want exact equality of them.\n",
    "     \n",
    "What do we try:\n",
    " * Vanilla RNN\n",
    " * Stack-augmented RNN\n",
    " \n",
    "We shall train them as Language Models (like in Seminar10) - by reading the sequence and predicting the next symbol.\n",
    "This time, however, we make predicitons on each time step and not just at the very end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let us generate the \"correct\" sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sequence(batch_size = 10,crop_length = 100 ):\n",
    "    \"\"\"\n",
    "    Generates sequence from pattern [0  1*n 2*m 3*(n+m)]\n",
    "    \"\"\"\n",
    "    sequences=[]\n",
    "    for i in range(batch_size):\n",
    "        seq = [0]\n",
    "        \n",
    "        \n",
    "        #fill in the \"seq\" list with exactly 'crop_length' elements\n",
    "        #from repeated patterns of [0  1*n 2*m 3*(n+m)],\n",
    "        # n,m - random integers rolled from 1 to 15 including both edges\n",
    "        # one can see the expected result sampels 2 cells below\n",
    "        \n",
    "        <your code here, working with seq>\n",
    "\n",
    "        \n",
    "        \n",
    "        assert len(seq) == crop_length\n",
    "        \n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences,dtype='int32')\n",
    "\n",
    "alphabet = np.array(list('|abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "map(''.join,map(alphabet.__getitem__,generate_sequence(25,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Expected result__ of the tab above should be a list of strings like these\n",
    "\n",
    "\n",
    "`\n",
    " ...\n",
    " '||aaaaaaaaabbbcccccccccccc|aaaabccccc|aaaaaaaaabbccccccccccc|aaaaaaaaabbbbccccccccccccc|aaaaaaaaaabb',\n",
    " '||aaaaaaaaaaaabbbbbbbbbbcccccccccccccccccccccc|aaaabbbbbbbbbbbbcccccccccccccccc|aaaabbbbbbbbcccccccc',\n",
    " '||aaaaaaabbbbbcccccccccccc|aaaaabbbbbbccccccccccc|aaaaaaaaaaaabbbbbccccccccccccccccc|abbbbbbbbbbbccc',\n",
    " '||aaaaaaaaaaaabbbbcccccccccccccccc|aaaaaaaabbbbbbbbcccccccccccccccc|aaaaaaaaaaaabbbbbbbbcccccccccccc',\n",
    " '||aaaaaaaaaaaaabcccccccccccccc|aaaaaaaaaaabbbbbbbbbbbbccccccccccccccccccccccc|aaaaaaaaaaaaaabbbbbbbb',\n",
    " '||abbbbccccc|aaaaabbbbbbbbbbbbccccccccccccccccc|aaaaaaaaaaaaabbbbbbbbbbbbccccccccccccccccccccccccc|a',\n",
    " '||aaaaaaaabbbbcccccccccccc|aaaabbbbbbbbbccccccccccccc|aaaaaaaaaaaabbbbbbbbbbbccccccccccccccccccccccc',\n",
    " '||aaaaaaaabbbbbbbbbbbbbccccccccccccccccccccc|aaaaaabbbbbbbbbbbbbbcccccccccccccccccccc|aaaaaaaaaaaaab',\n",
    " ...\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from metrics import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#formal tests\n",
    "gen_sequences = generate_sequence(1000,500)\n",
    "correctness_ratio, c_count_mae = get_metrics(gen_sequences,alphabet)\n",
    "\n",
    "# checking that all sequences consist of repeated pattern | a+ b+ c+\n",
    "assert correctness_ratio == 1.0\n",
    "# All sequences must have the C letter count equal to the sum of A and B letters\n",
    "assert c_count_mae == 0\n",
    "\n",
    "#Finally, the sample must have the correct shape\n",
    "assert len(gen_sequences) == 1000\n",
    "assert len(gen_sequences[0]) == 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы и глобальные переменные\n",
    "\n",
    "* Просто несколько чиселок, которые будут использоваться далее по коду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generated sequence length\n",
    "SEQ_LENGTH = 100\n",
    "\n",
    "# size of a singe minibatch\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# total number of iterations\n",
    "N_EPOCHS = 5000\n",
    "\n",
    "# how often (one in that number of epochs) to print learning progress\n",
    "REPORT_RATE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input letters sequence of shape [batch,sequence_elem]\n",
    "sequences_batch = T.matrix(dtype=\"int32\",name=\"reference_sequences\")\n",
    "\n",
    "#it's size (theano-expression)\n",
    "batch_size = sequences_batch.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train some vanilla RNN\n",
    "\n",
    "We are going to implement the graph below, defining a single step of RNN network.\n",
    "\n",
    "* time ticks go from left to right\n",
    "* inputs are at the bottom, outputs are at the top\n",
    "\n",
    "![scheme](./rnn.png)\n",
    "\n",
    "The key elements are \n",
    "* prev rnn state - input for previous RNN hidden state\n",
    "* input letter - previous letter (as an input)\n",
    "* next rnn state - new updated RNN hidden state\n",
    "* generate_letter - a single letter chosen from RNN output probabilities\n",
    "* everything else is just as simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import DenseLayer, ElemwiseSumLayer, InputLayer, EmbeddingLayer, NonlinearityLayer\n",
    "import agentnet\n",
    "from agentnet.resolver import ProbablisticResolver\n",
    "from agentnet.agent import Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#observation = input letter - previous letter input goes here\n",
    "output_shape = (None,)\n",
    "\n",
    "observation_layer = InputLayer(output_shape,name=\"obs_input\")\n",
    "\n",
    "\n",
    "# embedding\n",
    "n_tokens = len(alphabet)\n",
    "obs_embedding = EmbeddingLayer(observation_layer,\n",
    "                                              input_size=n_tokens,\n",
    "                                              output_size=n_tokens,\n",
    "                                              name = \"input_embedding\")\n",
    "\n",
    "\n",
    "\n",
    "# RNN memory\n",
    "\n",
    "#N hidden neurons\n",
    "n_hid_1 = 70\n",
    "\n",
    "#previous RNN state goes here\n",
    "#~ prev rnn state\n",
    "prev_rnn_layer = InputLayer((None,n_hid_1),name=\"prev_rnn_state\")\n",
    "\n",
    "\n",
    "#complete RNN  using the scheme above\n",
    "\n",
    "rnn_frominput = <dense layer with None nonlinearity, None bias(b)  n_hid_1, outputs, takign embedding as input>\n",
    "\n",
    "rnn_fromhidden = <dense layer with None nonlinearity, None bias(b)  n_hid_1, outputs, takign prev RNN state as input>\n",
    "\n",
    "\n",
    "rnn_sum = <elementwise sum of these(ElemwiseSumLayer)>\n",
    "\n",
    "rnn = <nonlinearity (any reasonable one, tanh for example)>\n",
    "\n",
    "\n",
    "\n",
    "# This dictionary contains pairs {new state layer: prev state for this layer}\n",
    "\n",
    "from collections import OrderedDict\n",
    "memory_dict = OrderedDict([\n",
    "            (rnn,prev_rnn_layer),\n",
    "    ])\n",
    "\n",
    "\n",
    "#letter probabilities\n",
    "\n",
    "probability_layer = DenseLayer(rnn,\n",
    "                                         num_units = n_tokens,\n",
    "                                         nonlinearity=  lasagne.nonlinearities.softmax,\n",
    "                                         name=\"policy_original\")\n",
    "\n",
    "#resolver - picks a letter given probabilities\n",
    "\n",
    "resolver = ProbablisticResolver(probability_layer,\n",
    "                                assume_normalized=True,\n",
    "                                name=\"resolver\")\n",
    "\n",
    "\n",
    "#check that input/output shape match (generated letters)\n",
    "assert tuple(lasagne.layers.get_output_shape(resolver)) == tuple(output_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Creating a recurrent generator that\n",
    "# - has 1 input - observation layer\n",
    "# - has a memory, defined in memory dict ( single RNN )\n",
    "# - generates letters given probabilities from probability layer\n",
    "# - picks letters at resolver layer - proportionally to probabilities\n",
    "\n",
    "agent = Generator(\n",
    "    observation_layer,\n",
    "    memory_dict,\n",
    "    probability_layer,\n",
    "    resolver\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's unroll the recurrence\n",
    "\n",
    "* In this case, we make agent observe the reference letters from the input variable above\n",
    "  * helps to speed up the training.\n",
    "* the output essentially mimics lasagne.layers.RecurrentLayer, GRU or LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5c0df9be44a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m sessions = agent.get_sessions(session_length=SEQ_LENGTH,\n\u001b[0m\u001b[0;32m      2\u001b[0m                              \u001b[0mrecorded_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequences_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                              batch_size=batch_size,)\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "sessions = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             recorded_sequences=sequences_batch,\n",
    "                             batch_size=batch_size,)\n",
    "\n",
    "\n",
    "# RNN hidden sequence(s) - wouldbe-generated letters  - probabilities\n",
    "agent_states,               action_seq,           probas_seq       =  sessions\n",
    "\n",
    "\n",
    "# taking a particular RNN (the only one in our case)\n",
    "rnn_seq = agent_states[rnn]\n",
    "\n",
    "\n",
    "# and yes - we only really needed the probas_seq out of all these lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest is like what you usually do with lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get weights\n",
    "weights = lasagne.layers.get_all_params(resolver,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_weights = int(T.sum([T.prod(w.shape) for w in weights]).eval())\n",
    "print \"Total weights:\", total_weights\n",
    "\n",
    "#if you are tinkering with network size - remove the next line\n",
    "assert  5200 < total_weights <= 5700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "* Use simple crossentropy, just like in the seminar 10\n",
    "* Only this time we make predictions for next letters at all time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# take all predictions but for last(since we don't know reference \"next\" letter for it)\n",
    "predicted_probas = probas_seq[:,:-1]\n",
    "\n",
    "# minimal probability threshld to avoid -Inf in crossentropy logarithm\n",
    "predicted_probas = T.maximum(predicted_probas,1e-10)\n",
    "\n",
    "# the reference answers - for 0-th \"next letters\" prediction - 1-st input letter, for 1-st - the 2nd input and so on\n",
    "# the 0-th reference can be thrown away\n",
    "references = sequences_batch[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "# the regular crossentropy\n",
    "model_loss = lasagne.objectives.categorical_crossentropy(\n",
    "    predicted_probas.reshape([-1,n_tokens]),\n",
    "    references.ravel()\n",
    ").mean()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#regularizer for spice\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "reg_l2 = regularize_network_params(resolver,l2)*10**-5\n",
    "loss = model_loss + reg_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updates = <your favorite optimizer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the entire thing.\n",
    "* First compilation with SEQ_LENGTH above 25 may take several mugs of coffee to complete\n",
    "* If you are using GPU - it takes these same mugs plus a cake.\n",
    "* Btw cake consists layers just like your RNN does. This was supposed to be philosophical.\n",
    "\n",
    "![canvas](http://www.rabstol.net/uploads/gallery/main/322/rabstol_net_cakes_30.jpg)\n",
    "\n",
    "* p.s Cake is a lie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([sequences_batch],[loss],updates=updates)\n",
    "evaluation_fun = theano.function([sequences_batch],[loss,model_loss,reg_l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generated sequences batch size goes here\n",
    "gen_batch_size = T.scalar('generated batch size','int32')\n",
    "\n",
    "\n",
    "# just like the previous time, but we omit the reference sequence, allowing generator\n",
    "# to use it's own outputs as next inputs\n",
    "_,generated_action_seq,_ = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             batch_size=gen_batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finishing that coffee\n",
    "get_sequences = theano.function([gen_batch_size],generated_action_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Right now our network knows nothing (like Jon Snow, but for <spoiler>)\n",
    "map(alphabet.__getitem__,get_sequences(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "* Just as usual - training for N iterations and computing metrics\n",
    "\n",
    "* We shall monitor 3 metrics - \n",
    " * llh - simply loglikelihood - expected to decrease over time\n",
    " * Correctness rate - what is the probability of generating the correct sequence format, matching \"^|a+b+c+\"\n",
    "   * expected to grow\n",
    " * C error rate\n",
    "   * among the correct sequences, what is the mean absolute error (MAE) between the amount of \"C\"s we generated and what we should have, taking As and Bs into account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "metrics = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    #породим строки\n",
    "    new_batch = generate_sequence(BATCH_SIZE,SEQ_LENGTH)\n",
    "    #Потренируем чудовище\n",
    "    train_fun(new_batch)\n",
    "    \n",
    "    #Once in a while, напечатаем метрики\n",
    "    if i % REPORT_RATE==0:\n",
    "        \n",
    "        loss_components = evaluation_fun(new_batch)\n",
    "        print \"iter:%i\\tfull:%.5f\\tllh:%.5f\\treg:%.5f\"%tuple([i]+map(float,loss_components))        \n",
    "        \n",
    "        metrics['crossentropy'][i]=float(loss_components[1])\n",
    "        \n",
    "\n",
    "        examples = get_sequences(1000)\n",
    "        \n",
    "        correctness_ratio,c_count_mae = get_metrics(examples,alphabet)\n",
    "        \n",
    "\n",
    "        metrics[\"correctness_rates\"][i] = correctness_ratio\n",
    "        metrics[\"c_count_errors\"][i]=c_count_mae\n",
    "        \n",
    "        print \"Correctness rate: %.5f\"%(correctness_ratio)\n",
    "        print \"MAE over C counts: %.5f\"%(c_count_mae)\n",
    "        \n",
    "        for tid_line in examples[:3]:\n",
    "            print ' '.join(map(alphabet.__getitem__,tid_line))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plt.figure(figsize=[14,8])\n",
    "    plt.plot(*zip(*sorted(metrics[metric].items(),key=lambda (k,v):k)),label=metric)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylabel(\"popugai\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_5_last = lambda metric_name: map(lambda v: v[1],sorted(metrics[metric_name].items(),key=lambda v:v[0])[-5:])\n",
    "\n",
    "\n",
    "# assert metrics are below thresholds\n",
    "\n",
    "assert min(get_5_last(\"crossentropy\")) <= 0.3\n",
    "assert min(get_5_last(\"c_count_errors\")) <= 3\n",
    "assert min(get_5_last(\"correctness_rates\")) >= 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remember the logs for future plots\n",
    "rnn_metrics = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack RNN\n",
    "\n",
    "Теперь заведём Stack-augmented RNN.\n",
    "\n",
    "Оригинальная статья - http://arxiv.org/abs/1503.01007\n",
    "(там есть картинки)\n",
    "\n",
    "Идея - давайте мы выделим нашей RNN-ке стэк, которым она сможет управлять при помощи трёх операций\n",
    "\n",
    "* push - сдвиг стэка на единицу вглубь, добавление входного элемента\n",
    "* pop - сдвиг всех элементов на единицу ближе к выходу\n",
    "* no-op - сохранение состояния стэка\n",
    "\n",
    "При этом все эти операции обобщены так, чтобы их можно было выполнять с коэффициентами от 0 до 1\n",
    "* 0 - операция не выполняется\n",
    "* 1 - операция выполняется в полной мере\n",
    "* что-то между - операция выполняется отчасти\n",
    "* При этом  \n",
    "  * `0 <= push, pop, no-op <= 1`\n",
    "  * `push + pop + no-op = 1`\n",
    "\n",
    "В итоге обновление стэка выглядит так\n",
    "\n",
    "```Stack(depth i, t+1) = push * Stack(depth i+1, t) + pop * Stack(depth i-1, t) + no-op * Stack(depth i, t)```\n",
    "\n",
    "\n",
    "* В качестве \"вводимого\" элемента для push можно использовать элемент, полученный из скрытого состояния сети\n",
    "* При выполнении pop, элемент стэка на максимальной глубине заполняется нулевыми значениями с соответствующим коэффициентом\n",
    "* Самое первое (depth 0) значение в стэке влияет на новое значение рекуррентного слоя\n",
    "\n",
    "\n",
    "\n",
    "Как это всё делать:\n",
    " * Создадим слой, реализующий стэковую память\n",
    " * Воткнём его в сеть\n",
    " * ???\n",
    " * PROFIT!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Стэковая память"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers.base import MergeLayer\n",
    "\n",
    "class StackAugmentation(MergeLayer):\n",
    "    def __init__(self,\n",
    "                 observation_input,\n",
    "                 prev_state_input,\n",
    "                 controls_layer,\n",
    "                 **kwargs):\n",
    "\n",
    "        \n",
    "        #default name\n",
    "        if \"name\" not in kwargs:\n",
    "            kwargs[\"name\"] = \"YetAnother\"+self.__class__.__name__\n",
    "        \n",
    "               \n",
    "        super(StackAugmentation, self).__init__([observation_input,prev_state_input,controls_layer], **kwargs)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def get_output_for(self, inputs, **kwargs):\n",
    "        \"\"\"\n",
    "            Нам на вход приходят\n",
    "             - вводимый элемент формы [None, ширина стэка]\n",
    "             - состояние стэка на предыдущем шаге, форма [None,глубина стэка, ширина стэка]\n",
    "             - вектор управления стэком, форма [None, 3] - push, pop и no-op соответственно\n",
    "             \n",
    "            На выход мы хотим новое состояние стэка\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #кто они\n",
    "        input_val,prev_stack,controls = inputs\n",
    "        assert input_val.ndim==2\n",
    "        \n",
    "        \n",
    "        #немного преобразований формы (чтобы вам не нужно было делать это самосттоятельно)\n",
    "        controls = controls.reshape([-1,3,1,1])    \n",
    "        input_val = input_val[:,None,:]\n",
    "        zeros_at_the_top = T.zeros_like(prev_stack[:,0,None,:])\n",
    "        \n",
    "        # операции управления стэком\n",
    "        a_push,a_pop,a_no_op = controls[:,0],controls[:,1],controls[:,2]\n",
    "        \n",
    "        \n",
    "        # Промежуточный этап - подготовим версии стэка, сдвинутые на единицу вверх или вниз.\n",
    "        # Дописывать крайние элементы проще всего через T.concatenate(axis=1) или T.horizontal_stack\n",
    "        \n",
    "        \n",
    "        \n",
    "        stack_popped = стэк, сдвинутый вниз на 1 единицу глубины(начало выброшено), в конец которого дописан zeros_at_the_top\n",
    "        \n",
    "        \n",
    "        stack_pushed = стэк, сдвинутый вверх на 1 единицу глубины (конец выброшен), в начало которого дописан input_val\n",
    "        \n",
    "        \n",
    "        new_stack = формула для нового стэка с использованием 3 сигналов управления и соответствующих вариаций стэка\n",
    "\n",
    "        return new_stack\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        \"\"\"\n",
    "        Ещё 1 обязательный для lasagne (но не для Вас) метод слоя - вычисление размерности выхода по размерностям входов\n",
    "        \"\"\"\n",
    "        observation_shape,last_memory_state_shape,controls_shape = input_shapes\n",
    "        \n",
    "        return last_memory_state_shape\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Струтктурная схема\n",
    "![canvas](stack-rnn.png)\n",
    "\n",
    "\n",
    "* А теперь вылезай из-под стола. На самом деле всё проще.\n",
    "* Всё, что не обведено жЫрной чОрной линией - уже было в предыдущей схеме\n",
    "* Prev stack / Next stack - предыдущее и новое состояния стэка\n",
    "* StackAugmentation - слой, который вы только что реализовали\n",
    "* Stack Input и Controls - просто Dense слои\n",
    "* First - это операция подсматривания в верхний элемент стака (SliceLayer)\n",
    "\n",
    "Для вашей простоты, RNN часть уже сделана по аналогии с предыдущей сетью \n",
    "* (если вам больше нравится ваша имплементация - просто скопируйте её)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#observation - сюда на каждом шаге подаётся очередная буква из входной последовательности\n",
    "output_shape = (None,)\n",
    "observation_layer = InputLayer(output_shape,name=\"obs_input\")\n",
    "\n",
    "\n",
    "# Token embedding\n",
    "n_tokens = len(alphabet)\n",
    "obs_embedding = EmbeddingLayer(observation_layer,\n",
    "                                              input_size=n_tokens,\n",
    "                                              output_size=n_tokens,\n",
    "                                              name = \"input_embedding\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#число нейронов в скрытом слое RNN - чуть меньше, чтобы сумма всех весов получилась такой же, как у RNN без стэка\n",
    "n_hid_1 = 64\n",
    "\n",
    "#Сюда прицепится предыдущее состояние RNN\n",
    "prev_rnn_layer = InputLayer((None,n_hid_1),name=\"prev_rnn_state\")\n",
    "\n",
    "\n",
    "# Сюда прицепится предыдущее стостояние стэка\n",
    "stack_width = 3\n",
    "stack_depth = 50\n",
    "\n",
    "prev_stack_layer = InputLayer((None,stack_depth,stack_width))\n",
    "\n",
    "\n",
    "\n",
    "# Controls\n",
    "stack_controls_layer = Слой управления стаком - принимает предыдущее состояние rnn и генерит 3 выхода, которые суммируются в 1 (softmax)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Stack input\n",
    "stack_input_layer = Полносвязный слой от того же входа, размером в 3 нейрона. В качестве нелинейности что угодно (tanh например)\n",
    "    \n",
    "    \n",
    "#новое состояние стэка  - используем вашу функцию обновления\n",
    "next_stack = StackAugmentation(stack_input_layer,\n",
    "                              prev_stack_layer,\n",
    "                              stack_controls_layer)\n",
    "\n",
    "\n",
    "#возьмём первый элемент стэка (First), чтобы использовать в RNN\n",
    "stack_top = lasagne.layers.SliceLayer(next_stack,0,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RNN memory\n",
    "\n",
    "\n",
    "#RNN from input\n",
    "rnn_frominput = DenseLayer(obs_embedding,\n",
    "                           num_units=n_hid_1,\n",
    "                           name= \"rnn input to hidden\",\n",
    "                           nonlinearity = None)\n",
    "\n",
    "\n",
    "#RNN from hidden\n",
    "\n",
    "rnn_fromhidden = DenseLayer(prev_rnn_layer,\n",
    "                            num_units=n_hid_1,\n",
    "                            name= \"rnn hidden to hidden\",\n",
    "                            nonlinearity = None)\n",
    "                            \n",
    "#RNN from stack\n",
    "rnn_fromstack = Обновление RNN на основании stack_top\n",
    "\n",
    "\n",
    "rnn_sum = ElemwiseSumLayer([\n",
    "        rnn_frominput,\n",
    "        rnn_fromhidden,\n",
    "        rnn_fromstack     \n",
    "    ],\n",
    "    name = \"rnn_sum\")\n",
    "#между прочим это RNN с тремя входами, один из которых зависит от её предыдущего состояние,\n",
    "#и лазанья такое уже не умеет\n",
    "\n",
    "rnn = NonlinearityLayer(rnn_sum,lasagne.nonlinearities.tanh,\n",
    "                        name = \"rnn nonlinearity\")\n",
    "\n",
    "\n",
    "\n",
    "# В этом словаре лежат пары  {выход скрытого состояния: вход скрытого состояния с предыдущего шага}\n",
    "# допишем сюда стэк\n",
    "from collections import OrderedDict\n",
    "memory_dict = OrderedDict([\n",
    "            (rnn,prev_rnn_layer),\n",
    "            (next_stack, prev_stack_layer)\n",
    "    ])\n",
    "\n",
    "\n",
    "#Вероятности букв\n",
    "\n",
    "probability_layer = lasagne.layers.DenseLayer(rnn,\n",
    "                                         num_units = n_tokens,\n",
    "                                         nonlinearity=  lasagne.nonlinearities.softmax,\n",
    "                                         name=\"policy_original\")\n",
    "\n",
    "#resolver - выбирает конкретную букву пропорционально вероятностям\n",
    "\n",
    "resolver = ProbablisticResolver(probability_layer,\n",
    "                                assume_normalized=True,\n",
    "                                name=\"resolver\")\n",
    "\n",
    "\n",
    "#Проверка, совпадают ли формы у состояний. Должна пройти, если вы не сделали чего-то ужасного\n",
    "assert tuple(lasagne.layers.get_output_shape(resolver)) == tuple(output_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Создаём рекуррентный генератор, который\n",
    "# - имеет 1 вход - observation layer\n",
    "# - имеет память, описанную в memory dict ( один слой RNN )\n",
    "# - генерирует буквы с вероятностями, полученными на probability layer\n",
    "# - принимает решение, какую букву генерить, на слое resolver layer - пропорционально вероятностям\n",
    "\n",
    "agent = Generator(\n",
    "    observation_layer,\n",
    "    memory_dict,\n",
    "    probability_layer,\n",
    "    resolver\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Получим веса - проследите, чтобы там были веса всех обучаемых частей стэка\n",
    "weights = lasagne.layers.get_all_params(resolver,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_weights = int(T.sum([T.prod(w.shape) for w in weights]).eval())\n",
    "print \"Всего весов:\", total_weights\n",
    "\n",
    "#если вы экспериментируете с размером нейронки - удалите следующую строку\n",
    "assert 5000 < total_weights <= 5500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy-paste time\n",
    "\n",
    "Ниже следует абсолютно тот же код, что и в случае с RNN \n",
    "- желающие могут проследить \n",
    "- только без комментариев и в одной массе.\n",
    "- почему для этого не созданы функции - чтобы было проще отлаживать\n",
    "- __от вас требуется только скопировать туда строчку с оптимизатором__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas_seq = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             recorded_sequences=sequences_batch,\n",
    "                             batch_size=batch_size,)[-1]\n",
    "\n",
    "model_loss = lasagne.objectives.categorical_crossentropy(\n",
    "    T.maximum(probas_seq[:,:-1],1e-10).reshape([-1,n_tokens]),\n",
    "    sequences_batch[:,1:].ravel()\n",
    ").mean()\n",
    "\n",
    "loss = model_loss + regularize_network_params(resolver,l2)*10**-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "updates = ваш любивый оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([sequences_batch],[loss],updates=updates)\n",
    "evaluation_fun = theano.function([sequences_batch],[loss,model_loss,reg_l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_batch_size = T.scalar('generated batch size','int32')\n",
    "generated_action_seq = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             batch_size=gen_batch_size,)[-2]\n",
    "get_sequences = theano.function([gen_batch_size],generated_action_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цикл обучения - Stack-augmented RNN\n",
    "\n",
    "* Всё как обычно - учимся и раз в 100 итераций считаем метрики\n",
    "\n",
    "* Метрики нас интересуют 3 - \n",
    " * llh - простой loglikelihood - должен падать +- шум\n",
    " * доля правильных последовательностей - с какой вероятностью rnn сгенерит подряд сколько-то a, потом b, потом c - и потом начнёт новую строку.\n",
    "   * для формалистов - доля строк, которые полностью матчатся регээкспом \"^|a+b+c+\"\n",
    "   * тоже должен в целом расти, пока не выйдёт на асимптоту близь единицы\n",
    " * ошибка в количестве C\n",
    "   * рассматриваем только \"правильные\" последовательности по определению из предыдущего пункта\n",
    "   * считаем количество букв a (n), количество букв b (m). Правильное количество букв с - n+m\n",
    "   * Считаем средний модуль разности между сгенерированным количеством С и правильным.\n",
    "   * Формально метрика называется mean absolute error или MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "metrics = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    #породим строки\n",
    "    new_batch = generate_sequence(BATCH_SIZE,SEQ_LENGTH)\n",
    "    #Потренируем чудовище\n",
    "    train_fun(new_batch)\n",
    "    \n",
    "    #Once in a while, напечатаем метрики\n",
    "    if i % REPORT_RATE==0:\n",
    "        \n",
    "        loss_components = evaluation_fun(new_batch)\n",
    "        print \"iter:%i\\tfull:%.5f\\tllh:%.5f\\treg:%.5f\"%tuple([i]+map(float,loss_components))        \n",
    "        \n",
    "        metrics['crossentropy'][i]=float(loss_components[1])\n",
    "        \n",
    "\n",
    "        examples = get_sequences(1000)\n",
    "        \n",
    "        correctness_ratio,c_count_mae = get_metrics(examples,alphabet)\n",
    "        \n",
    "\n",
    "        metrics[\"correctness_rates\"][i] = correctness_ratio\n",
    "        metrics[\"c_count_errors\"][i]=c_count_mae\n",
    "        \n",
    "        print \"Доля последовательностей правильной формы: %.5f\"%(correctness_ratio)\n",
    "        print \"MAE Ошибка по количеству C среди правильных: %.5f\"%(c_count_mae)\n",
    "        \n",
    "        for tid_line in examples[:3]:\n",
    "            print ' '.join(map(alphabet.__getitem__,tid_line))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_5_last = lambda metric_name: map(lambda v: v[1],sorted(metrics[metric_name].items(),key=lambda v:v[0])[-5:])\n",
    "\n",
    "\n",
    "#проверяем, что минимум по последним 5 значениям метрики не хуже порога\n",
    "\n",
    "assert min(get_5_last(\"crossentropy\")) <= 0.25\n",
    "assert min(get_5_last(\"c_count_errors\")) <= 1\n",
    "assert min(get_5_last(\"correctness_rates\")) >= 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кривулины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plt.figure(figsize=[14,8])\n",
    "    plt.plot(*zip(*sorted(metrics[metric].items(),key=lambda (k,v):k)),label='Stack RNN '+metric)\n",
    "    plt.plot(*zip(*sorted(rnn_metrics[metric].items(),key=lambda (k,v):k)),label='Simple RNN '+metric)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylabel(\"popugai\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Вопросы на CPU-time\n",
    "\n",
    "* Как изменится (и изменится ли) картина, если уменьшить/увеличить\n",
    " * количество нейронов в RNN в 2 раза больше/меньше как со стэком, так и без?\n",
    " * размер стэка (stack width) и его глубину? Какая минмальная глубина нужна, чтобы был видимый эффект?\n",
    " * сделать ещё 1+ стэк?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кто победил?\n",
    "\n",
    "Ну конечно же, <так кто же победил?>, однако <комментарии>\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### А ещё это последний семинар курса\n",
    "\n",
    "Вот так.\n",
    "Кто-то, возможно, уже забыл, что у потока домашек существует конец, а вот вы не забыли и героически до него дошли.\n",
    "\n",
    "Думаю, ни для кого не секрет, что далеко не всё в этом курсе было идеальным, или даже сносным, и многие уже успели рассказать нам, что именно нужно улучшать в первую очередь. \n",
    "\n",
    "Если вы ещё не вошли в их число - мы будем очень рады, если вы расскажите, чего вам хотелось бы побольше, что соблюдено в верной пропорции, а от чего лучше бы отказаться.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Ну, вот, например, тут.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![canvas](http://waytorussia.net/sites/default/files/hedgehog-fog-yozhik-v-tumane.jpg)\n",
    "\n",
    "Спасибо, что пережили с нами этот семестр:)\n",
    "\n",
    "Ваши cygnus, lidl и ёжик.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
