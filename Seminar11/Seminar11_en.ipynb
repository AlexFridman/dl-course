{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#theano imports\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "floatX = theano.config.floatX\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The library\n",
    "\n",
    "In this seminar we shall use [AgentNet](https://github.com/BladeCarrier/AgentNet/) library.\n",
    "Agentnet, in essence, is an additional kit of lasagne layers that allow you to build custom recurrent layers.\n",
    "Assuming you already have Bleeding Edge theano and lasagne, you can install it via\n",
    "```\n",
    "git clone https://github.com/yandexdataschool/AgentNet\n",
    "cd AgentNet\n",
    "python setup.py install\n",
    "```\n",
    "in whatever python, environment or container you exist. Alternatively, see docker install instructions in the [readme](https://github.com/yandexdataschool/AgentNet/blob/master/README.md).\n",
    "\n",
    "\n",
    "Depending what python version do you use, in may be \n",
    "* `python3 setup.py install` \\ `python2 setup.py install` if you are using a different python\n",
    "* add sudo - `sudo python setup.py install` - if you have a superuser-installed python\n",
    "* in case you have any problems - contact us or consider using a docker container (see above).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A friendly warning\n",
    "\n",
    "The problem we tackle here is of a relatively small scale, and so are the networks.\n",
    "You can, of course, use GPU, but it is likely to consume more of your time when compiling (seriously, up to some 20-30 minutes), than what it saves during execution.\n",
    "\n",
    "Consider switching to CPU and/or disabling optimization (theano.config.optimizer='None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack-augmented RNN\n",
    "![caption](https://usercontent1.hubstatic.com/6172838_f260.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's menu\n",
    "\n",
    "__The problem__ - train NN to generate sequences of `|`$ a^n b^m c^{n+m} $\n",
    " * n and m are positive integers picked randomly\n",
    " * What do we want exactly:\n",
    "  * Sequence must have a correct form - `|`, some __a__'s, some __b__'s, than some __c__'s and `|` again\n",
    "     * ||aaacbbcba would be a counterexample\n",
    "  * A number of C letters must be as close as possible to the number of A and B letters together\n",
    "     * Ideally, we want exact equality of them.\n",
    "     \n",
    "What do we try:\n",
    " * Vanilla RNN\n",
    " * Stack-augmented RNN\n",
    " \n",
    "We shall train them as Language Models (like in Seminar10) - by reading the sequence and predicting the next symbol.\n",
    "This time, however, we make predicitons on each time step and not just at the very end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let us generate the \"correct\" sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sequence(batch_size = 10,crop_length = 100 ):\n",
    "    \"\"\"\n",
    "    Generates sequence from pattern [0  1*n 2*m 3*(n+m)]\n",
    "    \"\"\"\n",
    "    sequences=[]\n",
    "    for i in range(batch_size):\n",
    "        seq = [0]\n",
    "        \n",
    "        \n",
    "        #fill in the \"seq\" list with exactly 'crop_length' elements\n",
    "        #from repeated patterns of [0  1*n 2*m 3*(n+m)],\n",
    "        # n,m - random integers rolled from 1 to 15 including both edges\n",
    "        # one can see the expected result sampels 2 cells below\n",
    "        \n",
    "        <your code here, working with seq>\n",
    "\n",
    "        \n",
    "        \n",
    "        assert len(seq) == crop_length\n",
    "        \n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences,dtype='int32')\n",
    "\n",
    "alphabet = np.array(list('|abc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "map(''.join,map(alphabet.__getitem__,generate_sequence(25,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Expected result__ of the tab above should be a list of strings like these\n",
    "\n",
    "\n",
    "`\n",
    " ...\n",
    " '||aaaaaaaaabbbcccccccccccc|aaaabccccc|aaaaaaaaabbccccccccccc|aaaaaaaaabbbbccccccccccccc|aaaaaaaaaabb',\n",
    " '||aaaaaaaaaaaabbbbbbbbbbcccccccccccccccccccccc|aaaabbbbbbbbbbbbcccccccccccccccc|aaaabbbbbbbbcccccccc',\n",
    " '||aaaaaaabbbbbcccccccccccc|aaaaabbbbbbccccccccccc|aaaaaaaaaaaabbbbbccccccccccccccccc|abbbbbbbbbbbccc',\n",
    " '||aaaaaaaaaaaabbbbcccccccccccccccc|aaaaaaaabbbbbbbbcccccccccccccccc|aaaaaaaaaaaabbbbbbbbcccccccccccc',\n",
    " '||aaaaaaaaaaaaabcccccccccccccc|aaaaaaaaaaabbbbbbbbbbbbccccccccccccccccccccccc|aaaaaaaaaaaaaabbbbbbbb',\n",
    " '||abbbbccccc|aaaaabbbbbbbbbbbbccccccccccccccccc|aaaaaaaaaaaaabbbbbbbbbbbbccccccccccccccccccccccccc|a',\n",
    " '||aaaaaaaabbbbcccccccccccc|aaaabbbbbbbbbccccccccccccc|aaaaaaaaaaaabbbbbbbbbbbccccccccccccccccccccccc',\n",
    " '||aaaaaaaabbbbbbbbbbbbbccccccccccccccccccccc|aaaaaabbbbbbbbbbbbbbcccccccccccccccccccc|aaaaaaaaaaaaab',\n",
    " ...\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from metrics import get_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#formal tests\n",
    "gen_sequences = generate_sequence(1000,500)\n",
    "correctness_ratio, c_count_mae = get_metrics(gen_sequences,alphabet)\n",
    "\n",
    "# checking that all sequences consist of repeated pattern | a+ b+ c+\n",
    "assert correctness_ratio == 1.0\n",
    "# All sequences must have the C letter count equal to the sum of A and B letters\n",
    "assert c_count_mae == 0\n",
    "\n",
    "#Finally, the sample must have the correct shape\n",
    "assert len(gen_sequences) == 1000\n",
    "assert len(gen_sequences[0]) == 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and global variables\n",
    "\n",
    "* Just some numbers that find their use farther in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generated sequence length\n",
    "SEQ_LENGTH = 100\n",
    "\n",
    "# size of a singe minibatch\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# total number of iterations\n",
    "N_EPOCHS = 5000\n",
    "\n",
    "# how often (one in that number of epochs) to print learning progress\n",
    "REPORT_RATE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input letters sequence of shape [batch,sequence_elem]\n",
    "sequences_batch = T.matrix(dtype=\"int32\",name=\"reference_sequences\")\n",
    "\n",
    "#it's size (theano-expression)\n",
    "batch_size = sequences_batch.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train some vanilla RNN\n",
    "\n",
    "We are going to implement the graph below, defining a single step of RNN network.\n",
    "\n",
    "* time ticks go from left to right\n",
    "* inputs are at the bottom, outputs are at the top\n",
    "\n",
    "![scheme](./rnn.png)\n",
    "\n",
    "The key elements are \n",
    "* prev rnn state - input for previous RNN hidden state\n",
    "* input letter - previous letter (as an input)\n",
    "* next rnn state - new updated RNN hidden state\n",
    "* generate_letter - a single letter chosen from RNN output probabilities\n",
    "* everything else is just as simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import DenseLayer, ElemwiseSumLayer, InputLayer, EmbeddingLayer, NonlinearityLayer\n",
    "import agentnet\n",
    "from agentnet.resolver import ProbablisticResolver\n",
    "from agentnet.agent import Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#observation = input letter - previous letter input goes here\n",
    "output_shape = (None,)\n",
    "\n",
    "observation_layer = InputLayer(output_shape,name=\"obs_input\")\n",
    "\n",
    "\n",
    "# embedding\n",
    "n_tokens = len(alphabet)\n",
    "obs_embedding = EmbeddingLayer(observation_layer,\n",
    "                                              input_size=n_tokens,\n",
    "                                              output_size=n_tokens,\n",
    "                                              name = \"input_embedding\")\n",
    "\n",
    "\n",
    "\n",
    "# RNN memory\n",
    "\n",
    "#N hidden neurons\n",
    "n_hid_1 = 70\n",
    "\n",
    "#previous RNN state goes here\n",
    "#~ prev rnn state\n",
    "prev_rnn_layer = InputLayer((None,n_hid_1),name=\"prev_rnn_state\")\n",
    "\n",
    "\n",
    "#complete RNN  using the scheme above\n",
    "\n",
    "rnn_frominput = <dense layer with None nonlinearity, None bias(b)  n_hid_1, outputs, takign embedding as input>\n",
    "\n",
    "rnn_fromhidden = <dense layer with None nonlinearity, None bias(b)  n_hid_1, outputs, takign prev RNN state as input>\n",
    "\n",
    "\n",
    "rnn_sum = <elementwise sum of these(ElemwiseSumLayer)>\n",
    "\n",
    "rnn = <nonlinearity (any reasonable one, tanh for example)>\n",
    "\n",
    "\n",
    "\n",
    "# This dictionary contains pairs {new state layer: prev state for this layer}\n",
    "\n",
    "from collections import OrderedDict\n",
    "memory_dict = OrderedDict([\n",
    "            (rnn,prev_rnn_layer),\n",
    "    ])\n",
    "\n",
    "\n",
    "#letter probabilities\n",
    "\n",
    "probability_layer = DenseLayer(rnn,\n",
    "                                         num_units = n_tokens,\n",
    "                                         nonlinearity=  lasagne.nonlinearities.softmax,\n",
    "                                         name=\"policy_original\")\n",
    "\n",
    "#resolver - picks a letter given probabilities\n",
    "\n",
    "resolver = ProbablisticResolver(probability_layer,\n",
    "                                assume_normalized=True,\n",
    "                                name=\"resolver\")\n",
    "\n",
    "\n",
    "#check that input/output shape match (generated letters)\n",
    "assert tuple(lasagne.layers.get_output_shape(resolver)) == tuple(output_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Creating a recurrent generator that\n",
    "# - has 1 input - observation layer\n",
    "# - has a memory, defined in memory dict ( single RNN )\n",
    "# - generates letters given probabilities from probability layer\n",
    "# - picks letters at resolver layer - proportionally to probabilities\n",
    "\n",
    "agent = Generator(\n",
    "    observation_layer,\n",
    "    memory_dict,\n",
    "    probability_layer,\n",
    "    resolver\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's unroll the recurrence\n",
    "\n",
    "* In this case, we make agent observe the reference letters from the input variable above\n",
    "  * helps to speed up the training.\n",
    "* the output essentially mimics lasagne.layers.RecurrentLayer, GRU or LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sessions = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             recorded_sequences=sequences_batch,\n",
    "                             batch_size=batch_size,)\n",
    "\n",
    "\n",
    "# RNN hidden sequence(s) - wouldbe-generated letters  - probabilities\n",
    "agent_states,               action_seq,           probas_seq       =  sessions\n",
    "\n",
    "\n",
    "# taking a particular RNN (the only one in our case)\n",
    "rnn_seq = agent_states[rnn]\n",
    "\n",
    "\n",
    "# and yes - we only really needed the probas_seq out of all these lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest is like what you usually do with lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get weights\n",
    "weights = lasagne.layers.get_all_params(resolver,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_weights = int(T.sum([T.prod(w.shape) for w in weights]).eval())\n",
    "print \"Total weights:\", total_weights\n",
    "\n",
    "#if you are tinkering with network size - remove the next line\n",
    "assert  5200 < total_weights <= 5700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "* Use simple crossentropy, just like in the seminar 10\n",
    "* Only this time we make predictions for next letters at all time steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# take all predictions but for last(since we don't know reference \"next\" letter for it)\n",
    "predicted_probas = probas_seq[:,:-1]\n",
    "\n",
    "# minimal probability threshld to avoid -Inf in crossentropy logarithm\n",
    "predicted_probas = T.maximum(predicted_probas,1e-10)\n",
    "\n",
    "# the reference answers - for 0-th \"next letters\" prediction - 1-st input letter, for 1-st - the 2nd input and so on\n",
    "# the 0-th reference can be thrown away\n",
    "references = sequences_batch[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "# the regular crossentropy\n",
    "model_loss = lasagne.objectives.categorical_crossentropy(\n",
    "    predicted_probas.reshape([-1,n_tokens]),\n",
    "    references.ravel()\n",
    ").mean()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#regularizer for spice\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "reg_l2 = regularize_network_params(resolver,l2)*10**-5\n",
    "loss = model_loss + reg_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updates = <your favorite optimizer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the entire thing.\n",
    "* First compilation with SEQ_LENGTH above 25 may take several mugs of coffee to complete\n",
    "* If you are using GPU - it takes these same mugs plus a cake.\n",
    "* Btw cake consists layers just like your RNN does. This was supposed to be philosophical.\n",
    "\n",
    "![canvas](http://www.rabstol.net/uploads/gallery/main/322/rabstol_net_cakes_30.jpg)\n",
    "\n",
    "* p.s Cake is a lie!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([sequences_batch],[loss],updates=updates)\n",
    "evaluation_fun = theano.function([sequences_batch],[loss,model_loss,reg_l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating new symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generated sequences batch size goes here\n",
    "gen_batch_size = T.scalar('generated batch size','int32')\n",
    "\n",
    "\n",
    "# just like the previous time, but we omit the reference sequence, allowing generator\n",
    "# to use it's own outputs as next inputs\n",
    "_,generated_action_seq,_ = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             batch_size=gen_batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finishing that coffee\n",
    "get_sequences = theano.function([gen_batch_size],generated_action_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Right now our network knows nothing (like Jon Snow, but for <spoiler>)\n",
    "map(alphabet.__getitem__,get_sequences(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "* Just as usual - training for N iterations and computing metrics\n",
    "\n",
    "* We shall monitor 3 metrics - \n",
    " * llh - simply loglikelihood - expected to decrease over time\n",
    " * Correctness rate - what is the probability of generating the correct sequence format, matching \"^|a+b+c+\"\n",
    "   * expected to grow\n",
    " * C error rate\n",
    "   * among the correct sequences, what is the mean absolute error (MAE) between the amount of \"C\"s we generated and what we should have, taking As and Bs into account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "metrics = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    #generate the sequences\n",
    "    new_batch = generate_sequence(BATCH_SIZE,SEQ_LENGTH)\n",
    "    #feed the beast\n",
    "    train_fun(new_batch)\n",
    "    \n",
    "    #Once in a while, display metrics\n",
    "    if i % REPORT_RATE==0:\n",
    "        \n",
    "        loss_components = evaluation_fun(new_batch)\n",
    "        print \"iter:%i\\tfull:%.5f\\tllh:%.5f\\treg:%.5f\"%tuple([i]+map(float,loss_components))        \n",
    "        \n",
    "        metrics['crossentropy'][i]=float(loss_components[1])\n",
    "        \n",
    "\n",
    "        examples = get_sequences(1000)\n",
    "        \n",
    "        correctness_ratio,c_count_mae = get_metrics(examples,alphabet)\n",
    "        \n",
    "\n",
    "        metrics[\"correctness_rates\"][i] = correctness_ratio\n",
    "        metrics[\"c_count_errors\"][i]=c_count_mae\n",
    "        \n",
    "        print \"Correctness rate: %.5f\"%(correctness_ratio)\n",
    "        print \"C count MAE for correct ones: %.5f\"%(c_count_mae)\n",
    "        \n",
    "        for tid_line in examples[:3]:\n",
    "            print ' '.join(map(alphabet.__getitem__,tid_line))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plt.figure(figsize=[14,8])\n",
    "    plt.plot(*zip(*sorted(metrics[metric].items(),key=lambda (k,v):k)),label=metric)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylabel(\"popugai\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_5_last = lambda metric_name: map(lambda v: v[1],sorted(metrics[metric_name].items(),key=lambda v:v[0])[-5:])\n",
    "\n",
    "\n",
    "# assert metrics are below thresholds\n",
    "\n",
    "assert min(get_5_last(\"crossentropy\")) <= 0.3\n",
    "assert min(get_5_last(\"c_count_errors\")) <= 3\n",
    "assert min(get_5_last(\"correctness_rates\")) >= 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remember the logs for future plots\n",
    "rnn_metrics = metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack RNN\n",
    "\n",
    "Here goes the Stack-augmented RNN.\n",
    "\n",
    "The original paper - http://arxiv.org/abs/1503.01007\n",
    "(with pictures)\n",
    "\n",
    "Let's allocate a stack for out RNN to store data in. The stack has  control operations\n",
    "\n",
    "* push - pushing stack one element deeper, adding input element\n",
    "* pop - move everything one element shallower, removing the top\n",
    "* no-op - preserving the previous state\n",
    "\n",
    "The operations are generalized to allow performing them to an extent from 0 to 1\n",
    "* 0 - operation not applied\n",
    "* 1 - operation applied as in the regular stack\n",
    "* Anything inbetween - operation is partially applied \n",
    "* Constraints\n",
    "  * `0 <= push, pop, no-op <= 1`\n",
    "  * `push + pop + no-op = 1`\n",
    "\n",
    "The stack update rule looks thus:\n",
    "\n",
    "```Stack(depth i, t+1) = push * Stack(depth i+1, t) + pop * Stack(depth i-1, t) + no-op * Stack(depth i, t)```\n",
    "\n",
    "\n",
    "* The \"Input\" element for push is yet another dense layer dependent on hidden RNN state\n",
    "* When doing pop, the stack is padded with zeros from the bottom (deepest, farthest from input)\n",
    "* The first (depth 0) stack value is given as an input to the recurrent layer\n",
    "\n",
    "\n",
    "\n",
    "How do we implement it?\n",
    " * Create a layer implementing one step of stack memory\n",
    " * Plug it into network\n",
    " * ???\n",
    " * PROFIT!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers.base import MergeLayer\n",
    "\n",
    "class StackAugmentation(MergeLayer):\n",
    "    def __init__(self,\n",
    "                 observation_input,\n",
    "                 prev_state_input,\n",
    "                 controls_layer,\n",
    "                 **kwargs):\n",
    "\n",
    "        \n",
    "        #default name\n",
    "        if \"name\" not in kwargs:\n",
    "            kwargs[\"name\"] = \"YetAnother\"+self.__class__.__name__\n",
    "        \n",
    "               \n",
    "        super(StackAugmentation, self).__init__([observation_input,prev_state_input,controls_layer], **kwargs)\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def get_output_for(self, inputs, **kwargs):\n",
    "        \"\"\"\n",
    "            Inputs\n",
    "             - input element of shape [None, stack width]\n",
    "             - previous stack state of shape [None,stack depth, stack width]\n",
    "             - vector controls of shape [None, 3] - push, pop and no-op accordingly\n",
    "             \n",
    "            This function should return the updated stack state.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        #unpack inputs\n",
    "        input_val,prev_stack,controls = inputs\n",
    "        assert input_val.ndim==2\n",
    "        \n",
    "        \n",
    "        #some shape transformations to make your math smoother\n",
    "        controls = controls.reshape([-1,3,1,1])    \n",
    "        input_val = input_val[:,None,:]\n",
    "        zeros_at_the_top = T.zeros_like(prev_stack[:,0,None,:])\n",
    "        \n",
    "        # stack control operations\n",
    "        a_push,a_pop,a_no_op = controls[:,0],controls[:,1],controls[:,2]\n",
    "        \n",
    "        \n",
    "        # Intermediate stage - prepare stack versions, shifted one row down (push) and up(pop)\n",
    "        # Adding the edge elements (input and last element) is easier via T.concatenate(axis=1) or T.horizontal_stack\n",
    "        \n",
    "        \n",
    "        \n",
    "        stack_popped = <stack shifted 1 row up, first element thrown away, stack end padded with zeros_at_the_top>\n",
    "        \n",
    "        \n",
    "        stack_pushed = <stack shifted 1 row down, deepest element forgotten, new first element is input_val>        \n",
    "        \n",
    "        new_stack = <a formula for new stack state using 3 controls>\n",
    "\n",
    "        return new_stack\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        \"\"\"\n",
    "        A lasagne layer method that returns output shape - already implemented for you.\n",
    "        \"\"\"\n",
    "        observation_shape,last_memory_state_shape,controls_shape = input_shapes\n",
    "        \n",
    "        return last_memory_state_shape\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackRNN structur\n",
    "![canvas](stack-rnn.png)\n",
    "\n",
    "\n",
    "* Brace yourselves! It will turn out simpler than it seems\n",
    "* Every new componemt has a __bold black__ frame, the rest is vanilla RNN\n",
    "* Prev stack / Next stack - previous and new stack states\n",
    "* StackAugmentation - the stack autmentation layer you have just implemented\n",
    "* Stack Input и Controls - simple Dense layers\n",
    "* First - An operation of taking the outermost stack element (SliceLayer)\n",
    "\n",
    "To save your time, the vanilla RNN is already implemented here so that you could focus on stack augmentation.\n",
    "* If you prefer your own implementation, just copy-paste it where appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#observation - previous generated letter goes here\n",
    "output_shape = (None,)\n",
    "observation_layer = InputLayer(output_shape,name=\"obs_input\")\n",
    "\n",
    "\n",
    "# Token embedding\n",
    "n_tokens = len(alphabet)\n",
    "obs_embedding = EmbeddingLayer(observation_layer,\n",
    "                                              input_size=n_tokens,\n",
    "                                              output_size=n_tokens,\n",
    "                                              name = \"input_embedding\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#RNN hidden state size - a bit smaller to compensate for stack controls\n",
    "n_hid_1 = 64\n",
    "\n",
    "#previous RNN state goes here\n",
    "prev_rnn_layer = InputLayer((None,n_hid_1),name=\"prev_rnn_state\")\n",
    "\n",
    "\n",
    "# previous stack state is defined here\n",
    "stack_width = 3\n",
    "stack_depth = 50\n",
    "\n",
    "prev_stack_layer = InputLayer((None,stack_depth,stack_width))\n",
    "\n",
    "\n",
    "\n",
    "# Controls\n",
    "stack_controls_layer = <stack controls layer - takes RNN hidden state and outputs 3 neurons whose output sum to 1 (softmax or norm)>\n",
    "\n",
    "\n",
    "# Stack input\n",
    "stack_input_layer = <a dense layer with any(say, tanh) nonlinearity, used to represent stack inputs for pushing>\n",
    "    \n",
    "    \n",
    "#Get the new stack state using your update function\n",
    "next_stack = StackAugmentation(stack_input_layer,\n",
    "                              prev_stack_layer,\n",
    "                              stack_controls_layer)\n",
    "\n",
    "\n",
    "#Take stack top (First) to feed it into RNN\n",
    "stack_top = lasagne.layers.SliceLayer(next_stack,0,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RNN memory\n",
    "\n",
    "\n",
    "#RNN from input\n",
    "rnn_frominput = DenseLayer(obs_embedding,\n",
    "                           num_units=n_hid_1,\n",
    "                           name= \"rnn input to hidden\",\n",
    "                           b = None\n",
    "                           nonlinearity = None)\n",
    "\n",
    "\n",
    "#RNN from hidden\n",
    "\n",
    "rnn_fromhidden = DenseLayer(prev_rnn_layer,\n",
    "                            num_units=n_hid_1,\n",
    "                            name= \"rnn hidden to hidden\",\n",
    "                            nonlinearity = None,)\n",
    "                            \n",
    "#RNN from stack\n",
    "rnn_fromstack = <RNN updates based on stack_top>\n",
    "\n",
    "rnn_sum = ElemwiseSumLayer([\n",
    "        rnn_frominput,\n",
    "        rnn_fromhidden,\n",
    "        rnn_fromstack     \n",
    "    ],\n",
    "    name = \"rnn_sum\")\n",
    "# this thing above is essencially a 3-input RNN\n",
    "\n",
    "rnn = NonlinearityLayer(rnn_sum,lasagne.nonlinearities.tanh,\n",
    "                        name = \"rnn nonlinearity\")\n",
    "\n",
    "\n",
    "\n",
    "# This dictionary maps {hidden state outputs : hidden_state_inputs}\n",
    "# with stack now among them.\n",
    "from collections import OrderedDict\n",
    "memory_dict = OrderedDict([\n",
    "            (rnn,prev_rnn_layer),\n",
    "            (next_stack, prev_stack_layer)\n",
    "    ])\n",
    "\n",
    "\n",
    "#next letter probabilities\n",
    "\n",
    "probability_layer = lasagne.layers.DenseLayer(rnn,\n",
    "                                         num_units = n_tokens,\n",
    "                                         nonlinearity=  lasagne.nonlinearities.softmax,\n",
    "                                         name=\"policy_original\")\n",
    "\n",
    "#resolver - picks the next letter as before\n",
    "\n",
    "resolver = ProbablisticResolver(probability_layer,\n",
    "                                assume_normalized=True,\n",
    "                                name=\"resolver\")\n",
    "\n",
    "\n",
    "#input/output shape check\n",
    "assert tuple(lasagne.layers.get_output_shape(resolver)) == tuple(output_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Creating a generator, again, just liek before\n",
    "\n",
    "agent = Generator(\n",
    "    observation_layer,\n",
    "    memory_dict,\n",
    "    probability_layer,\n",
    "    resolver\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get weights - make sure all stack-related parameters are there\n",
    "weights = lasagne.layers.get_all_params(resolver,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_weights = int(T.sum([T.prod(w.shape) for w in weights]).eval())\n",
    "print \"Total weights:\", total_weights\n",
    "\n",
    "#if you are experimenting with network size, remove the next line\n",
    "assert 5000 < total_weights <= 5500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy-paste time\n",
    "\n",
    "Here comes the same code used to train RNN \n",
    "- but now it's packed a bit more tightly\n",
    "- __everything you need is to copy-paste optimizer line there__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probas_seq = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             recorded_sequences=sequences_batch,\n",
    "                             batch_size=batch_size,)[-1]\n",
    "\n",
    "model_loss = lasagne.objectives.categorical_crossentropy(\n",
    "    T.maximum(probas_seq[:,:-1],1e-10).reshape([-1,n_tokens]),\n",
    "    sequences_batch[:,1:].ravel()\n",
    ").mean()\n",
    "\n",
    "loss = model_loss + regularize_network_params(resolver,l2)*10**-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "updates = <Your favorite optimizer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([sequences_batch],[loss],updates=updates)\n",
    "evaluation_fun = theano.function([sequences_batch],[loss,model_loss,reg_l2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_batch_size = T.scalar('generated batch size','int32')\n",
    "generated_action_seq = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             batch_size=gen_batch_size,)[-2]\n",
    "get_sequences = theano.function([gen_batch_size],generated_action_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop - Stack-Augmented RNN\n",
    "\n",
    "* Just as usual - training for N iterations and computing metrics\n",
    "\n",
    "* We shall monitor 3 metrics - \n",
    " * llh - simply loglikelihood - expected to decrease over time\n",
    " * Correctness rate - what is the probability of generating the correct sequence format, matching \"^|a+b+c+\"\n",
    "   * expected to grow\n",
    " * C error rate\n",
    "   * among the correct sequences, what is the mean absolute error (MAE) between the amount of \"C\"s we generated and what we should have, taking As and Bs into account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "metrics = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    #generate sequences\n",
    "    new_batch = generate_sequence(BATCH_SIZE,SEQ_LENGTH)\n",
    "    #feed the beast\n",
    "    train_fun(new_batch)\n",
    "    \n",
    "    #Once in a while, display metrics\n",
    "    if i % REPORT_RATE==0:\n",
    "        \n",
    "        loss_components = evaluation_fun(new_batch)\n",
    "        print \"iter:%i\\tfull:%.5f\\tllh:%.5f\\treg:%.5f\"%tuple([i]+map(float,loss_components))        \n",
    "        \n",
    "        metrics['crossentropy'][i]=float(loss_components[1])\n",
    "        \n",
    "\n",
    "        examples = get_sequences(1000)\n",
    "        \n",
    "        correctness_ratio,c_count_mae = get_metrics(examples,alphabet)\n",
    "        \n",
    "\n",
    "        metrics[\"correctness_rates\"][i] = correctness_ratio\n",
    "        metrics[\"c_count_errors\"][i]=c_count_mae\n",
    "        \n",
    "        print \"Correctness rate: %.5f\"%(correctness_ratio)\n",
    "        print \"C mean absolut error: %.5f\"%(c_count_mae)\n",
    "        \n",
    "        for tid_line in examples[:3]:\n",
    "            print ' '.join(map(alphabet.__getitem__,tid_line))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "get_5_last = lambda metric_name: map(lambda v: v[1],sorted(metrics[metric_name].items(),key=lambda v:v[0])[-5:])\n",
    "\n",
    "\n",
    "#quality thresholds\n",
    "\n",
    "assert min(get_5_last(\"crossentropy\")) <= 0.25\n",
    "assert min(get_5_last(\"c_count_errors\")) <= 1\n",
    "assert min(get_5_last(\"correctness_rates\")) >= 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plt.figure(figsize=[14,8])\n",
    "    plt.plot(*zip(*sorted(metrics[metric].items(),key=lambda (k,v):k)),label='Stack RNN '+metric)\n",
    "    plt.plot(*zip(*sorted(rnn_metrics[metric].items(),key=lambda (k,v):k)),label='Simple RNN '+metric)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylabel(\"popugai\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Quest for CPU-time\n",
    "\n",
    "* Will the results change (and how) if you divide neuron counts by 2 for both cases?\n",
    "* What if we change stack width and it's depth? What minamal depth achieves any reasonable effect?\n",
    "* What if we use several stacks?\n",
    "* Finally, what happens if we generate longer/shorter sequences? (make sure they are still within sequence length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay, who won after all?\n",
    "\n",
    "Certainly {that guy}, however {comments}\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n",
    "` `\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### And, well, you have just crossed the finish line\n",
    "\n",
    "Someone may have already forgotten, that homework assignments are finite, but you survived and cut through all of them in a heroic charge.\n",
    "\n",
    "We all know that this course was far from ideal, and at times, from decent, and some of you have already given us feedback, and we would be glad to have yours too. Tell us, what was okay, where we have gone too far and what was in direst need of improvement.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Someplace... Here, for example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![canvas](http://waytorussia.net/sites/default/files/hedgehog-fog-yozhik-v-tumane.jpg)\n",
    "\n",
    "And yes, thank you for surviving that course with us :)\n",
    "\n",
    "Yours,\n",
    "cygnus, lidl and 'da hedgehog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
