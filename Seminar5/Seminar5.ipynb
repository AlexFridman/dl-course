{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Seminar 5: Deep Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import cPickle as pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from lasagne.utils import floatX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import NonlinearityLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.layers import Pool2DLayer as PoolLayer\n",
    "from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "\n",
    "IMAGE_W = 224\n",
    "\n",
    "#vgg19 model\n",
    "#http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "def build_model():\n",
    "    net = {}\n",
    "    net['input'] = InputLayer((None, 3, 224, 224))\n",
    "    net['conv1_1'] = ConvLayer(net['input'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['conv1_2'] = ConvLayer(net['conv1_1'], 64, 3, pad=1, flip_filters=False)\n",
    "    net['pool1'] = PoolLayer(net['conv1_2'], 2)\n",
    "    net['conv2_1'] = ConvLayer(net['pool1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['conv2_2'] = ConvLayer(net['conv2_1'], 128, 3, pad=1, flip_filters=False)\n",
    "    net['pool2'] = PoolLayer(net['conv2_2'], 2)\n",
    "    net['conv3_1'] = ConvLayer(net['pool2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_2'] = ConvLayer(net['conv3_1'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_3'] = ConvLayer(net['conv3_2'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['conv3_4'] = ConvLayer(net['conv3_3'], 256, 3, pad=1, flip_filters=False)\n",
    "    net['pool3'] = PoolLayer(net['conv3_4'], 2)\n",
    "    net['conv4_1'] = ConvLayer(net['pool3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_2'] = ConvLayer(net['conv4_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_3'] = ConvLayer(net['conv4_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv4_4'] = ConvLayer(net['conv4_3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool4'] = PoolLayer(net['conv4_4'], 2)\n",
    "    net['conv5_1'] = ConvLayer(net['pool4'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_2'] = ConvLayer(net['conv5_1'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_3'] = ConvLayer(net['conv5_2'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['conv5_4'] = ConvLayer(net['conv5_3'], 512, 3, pad=1, flip_filters=False)\n",
    "    net['pool5'] = PoolLayer(net['conv5_4'], 2)\n",
    "    net['fc6'] = DenseLayer(net['pool5'], num_units=4096)\n",
    "    net['fc6_dropout'] = DropoutLayer(net['fc6'], p=0.5)\n",
    "    net['fc7'] = DenseLayer(net['fc6_dropout'], num_units=4096)\n",
    "    net['fc7_dropout'] = DropoutLayer(net['fc7'], p=0.5)\n",
    "    net['fc8'] = DenseLayer(net['fc7_dropout'], num_units=1000, nonlinearity=None)\n",
    "    net['prob'] = NonlinearityLayer(net['fc8'], softmax)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classes' names are stored here\n",
    "classes = pickle.load(open('classes.pkl'))\n",
    "#for example, 10th class is ostrich:\n",
    "print classes[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to implement two functions in the cell below.\n",
    "\n",
    "Preprocess function should take the image with shape (w, h, 3) and transform it into a tensor with shape (1, 3, 224, 224). Without this transformation, vgg19 won't be able to digest input image. \n",
    "Additionally, your preprocessing function have to rearrange channels RGB -> BGR and subtract mean values from every channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MEAN_VALUES = np.array([104, 117, 123])\n",
    "IMAGE_W = 224\n",
    "\n",
    "def preprocess(img):\n",
    "    pass\n",
    "\n",
    "def deprocess(img):\n",
    "    pass\n",
    "\n",
    "img = np.random.rand(IMAGE_W, IMAGE_W, 3)\n",
    "if not np.all(deprocess(preprocess(img)) == img):\n",
    "    print \"\"\"Either your implementation is incorrect, or floating point arithmetic is pulling some tricks\n",
    "anyway, the idea is that deprocess function is the inverse of preprocess function\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load model weights\n",
    "#vgg19.npz is available for download at\n",
    "#https://yadi.sk/d/UQPXeM_GqEmGg\n",
    "net = build_model()\n",
    "params = np.load('vgg19.npz')['params']\n",
    "for i in range(32,len(params)):\n",
    "    params[i] = params[i].T\n",
    "lasagne.layers.set_all_param_values(net.values(), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_image = T.tensor4('input')\n",
    "output = lasagne.layers.get_output(net['prob'], input_image)\n",
    "prob = theano.function([input_image], output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, you can test your preprocessing function on some sample images. If it is implemented correctly, **albatross.jpg** will be classified as albatross with 99.9% certainty, and with other pictures the network will produce mostly meaningful result.\n",
    "\n",
    "You can notice that network output varies from run to run. This behaviour can be supressed with help of \"deterministic\" keyword in get_output function in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = imread('sample_images/albatross.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "p = prob(preprocess(img))\n",
    "\n",
    "labels = p.ravel().argsort()[-1:-6:-1]\n",
    "print 'top-5 classes are:'\n",
    "for l in labels:\n",
    "    print '%3f\\t%s' % (p.ravel()[l], classes[l].split(',')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use vgg19 network and your knowledge of machine learning to classify cats and dogs!\n",
    "\n",
    "data: https://yadi.sk/d/m6ZO4BvWqEmR9\n",
    "\n",
    "**catsvsdogs/val/** validation images\n",
    "\n",
    "**catsvsdogs/val_labels.pickle** labels for validation images\n",
    "\n",
    "**catsvsdogs/test/** test images\n",
    "\n",
    "You have to implement classification algorithm, tune it on validation images, save output of your algorithm on test images in form of pickled file, as shown below. Your results, as well as this notebook, have to be attached to your letter to rdlclass@yandex.ru\n",
    "\n",
    "I expect classification accuracy >95%, or >90% at least\n",
    "\n",
    "Cheating is not allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(img):\n",
    "    if np.random.rand() > 0.5:\n",
    "        return 'cat'\n",
    "    else:\n",
    "        return 'dog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'catsvsdogs/test/'\n",
    "files = os.listdir(path)\n",
    "\n",
    "labels = []\n",
    "\n",
    "for f in files:\n",
    "    img = imread(path + f)\n",
    "    label = classify(img)\n",
    "    labels.append(label)\n",
    "    \n",
    "pickle.dump(labels, open('test_labels.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Visualizations\n",
    "\n",
    "It is easy to visualize the weights of the first convolutional layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = net['conv1_1'].W.eval().copy()\n",
    "w -= w.min()\n",
    "w /= w.max()\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        n = 8*j + i\n",
    "        if n < 64:\n",
    "            plt.subplot(8,8,n)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(w[n,:,:,:].transpose((1,2,0)), interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On higher layers, filters have more than 3 channels, so it is impossible to visualize them directly. However, of we want to understand something about features on higher layers, it is possible to visualize them via optimization of the input image.\n",
    "\n",
    "Namely, we can solve the following problem\n",
    "\n",
    "$$J=\\mathrm{argmax} \\left( n^i_{xyc}(I) \\right)$$\n",
    "\n",
    "there $n^i_{xyc}$ is the activation of neuron on $i$'th layer in position $x$,$y$,$c$ given input image $I$.\n",
    "Basically, $J$ is the answer on a question \"what our neuron is looking for?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_image = theano.shared(floatX(np.zeros((1, 3, IMAGE_W, IMAGE_W))))\n",
    "gen_features = lasagne.layers.get_output(net.values(), generated_image)\n",
    "gen_features = {k: v for k, v in zip(net.keys(), gen_features)}\n",
    "\n",
    "layer_name = 'pool1'\n",
    "c = 0\n",
    "blob_width = gen_features[layer_name].shape[2]\n",
    "x = blob_width/2\n",
    "y = blob_width/2\n",
    "loss = 1e10*(1e1 - gen_features[layer_name][0, c, x, y])**2\n",
    "\n",
    "grad = T.grad(loss, generated_image)\n",
    "\n",
    "tv_loss = T.mean(T.abs_(generated_image[:,:,1:,1:] - generated_image[:,:,:-1,1:]) +\n",
    "                 T.abs_(generated_image[:,:,1:,1:] - generated_image[:,:,1:,:-1]))\n",
    "\n",
    "f_loss = theano.function([], loss + 1.0 * tv_loss)\n",
    "f_grad = theano.function([], grad)\n",
    "\n",
    "# Helper functions to interface with scipy.optimize\n",
    "def eval_loss(x0):\n",
    "    x_ = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x_)\n",
    "    return f_loss().astype('float64')\n",
    "\n",
    "def eval_grad(x0):\n",
    "    x0 = floatX(x0.reshape((1, 3, IMAGE_W, IMAGE_W)))\n",
    "    generated_image.set_value(x0)\n",
    "    return np.array(f_grad()).flatten().astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run input image optimization via scipy.optimize.fmin_l_bfgs_b\n",
    "generated_image.set_value(floatX(np.zeros((1, 3, IMAGE_W, IMAGE_W))))\n",
    "x0 = generated_image.get_value().astype('float64')\n",
    "status = scipy.optimize.fmin_l_bfgs_b(eval_loss, x0.flatten(), fprime=eval_grad, maxfun=20)\n",
    "x0 = generated_image.get_value().astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your **deprocess** function is implemented correctly, you'll see that the neuron on the first pooling layer is looking for. The result should look like gabor filter, simular to ones found in the first layer of networks with large filters, such as AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#show the results\n",
    "w = IMAGE_W\n",
    "for d in [112, 64, 32, 16, 8]:\n",
    "    pic = deprocess(x0)[w/2-d:w/2+d,w/2-d:w/2+d,:]\n",
    "    pic -= pic.min()\n",
    "    pic /= pic.max()\n",
    "    plt.imshow(pic, interpolation='None')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional problem:\n",
    "Adjust the code above to work with neurons on fc8 layer.\n",
    "\n",
    "\n",
    "fc8 neurons are wired to output classes, so maximization of neuron value will produce an image which contains as much of given class (from the point of view of neural network) as possible. \n",
    "\n",
    "Examples of such images are shown at:\n",
    "\n",
    "http://yosinski.com/deepvis\n",
    "\n",
    "http://googleresearch.blogspot.ru/2015/06/inceptionism-going-deeper-into-neural.html\n",
    "\n",
    "http://auduno.com/post/125362849838/visualizing-googlenet-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
