{
 "metadata": {
  "name": "",
  "signature": "sha256:c73d095808d16b1bc215edb7ef6a3d2ac4b815cab5915985a73a6ef3c81c6af2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline\n",
      "\n",
      "import numpy as np\n",
      "from matplotlib import pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Face recognition"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this seminar is to build two simple (anv very similar) face recognition pipelines using **`scikit-learn`** package. Overall, we'd like to explore different representations and see which one works better. "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Prepare dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.io\n",
      "\n",
      "image_h, image_w = 32, 32\n",
      "\n",
      "data = scipy.io.loadmat('faces_data.mat')\n",
      "\n",
      "X_train = data['train_faces'].reshape((image_w, image_h, -1)).transpose((2, 1, 0)).reshape((-1, image_h * image_w))\n",
      "y_train = data['train_labels'] - 1\n",
      "X_test = data['test_faces'].reshape((image_w, image_h, -1)).transpose((2, 1, 0)).reshape((-1, image_h * image_w))\n",
      "y_test = data['test_labels'] - 1\n",
      "\n",
      "n_features = X_train.shape[1]\n",
      "n_train = len(y_train)\n",
      "n_test = len(y_test)\n",
      "n_classes = len(np.unique(y_train))\n",
      "\n",
      "print('Dataset loaded.')\n",
      "print('  Image size        : {}x{}'.format(image_h, image_w))\n",
      "print('  Train images      : {}'.format(n_train))\n",
      "print('  Test images       : {}'.format(n_test))\n",
      "print('  Number of classes : {}'.format(n_classes))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are going to plot some samples from the dataset using the provided helper function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_gallery(images, titles, h, w, n_row=3, n_col=6):\n",
      "    \"\"\"Helper function to plot a gallery of portraits\"\"\"\n",
      "    plt.figure(figsize=(1.5 * n_col, 1.7 * n_row))\n",
      "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
      "    for i in range(n_row * n_col):\n",
      "        plt.subplot(n_row, n_col, i + 1)\n",
      "        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray, interpolation='nearest')\n",
      "        plt.title(titles[i], size=12)\n",
      "        plt.xticks(())\n",
      "        plt.yticks(())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "titles = [str(y[0]) for y in y_train]\n",
      "\n",
      "plot_gallery(X_train, titles, image_h, image_w)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Nearest Neighbour baseline"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The simplest way to do face recognition is to treat raw pixels as features and perform **Nearest Neighbor Search** in the Euclidean space. Let's use **`KNeighborsClassifier`** class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "# Use KNeighborsClassifier to calculate test score for the Nearest Neighbour classifier.\n",
      "\n",
      "print('Test score: {}'.format(test_score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not very imperssive, is it?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sparse Coding time"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All the dirty work will be done by the **`scikit-learn`** package. First we need to learn a dictionary of codewords. For that we preprocess the training set by making each face normalized (zero mean and unit variance)..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Populate variable 'X_train_processed' with samples each of which has zero mean and unit variance."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and use **`DictionaryLearning`** class to obtain a dictionary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import DictionaryLearning\n",
      "\n",
      "n_components = 64\n",
      "\n",
      "# Populate variable 'sc' with a trained DictionaryLearning instance."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's plot some learned codewords."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize codewords using the provided helper function plot_gallery."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we map our data onto the sparse codes space..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.transform_n_nonzero_coefs = 10 \n",
      "X_train_encoded = sc.transform(X_train_processed)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and verify that the new representation is indeed sparse. What is clearly noticeable about the training data layout?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(10, 10))\n",
      "plt.imshow(X_train_encoded[: 64, :], cmap=plt.cm.gray, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's see if sparse codes give better results than naive nearest neighbour."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "# 1. Train LinearSVC using 'X_train_encoded' and 'y_train';\n",
      "# 2. Preprocess and map test data onto sparse code space;\n",
      "# 3. Test trained SVM against obtained test data (populate 'test_score');\n",
      "\n",
      "print('Test score: {}'.format(test_score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a bonus, let's experiment with the number of non-zero coefficients ans see how it affects the classification accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_nonzero = [1, 2, 4, 8, 16, 32, 64]\n",
      "accuracy = []\n",
      "\n",
      "# Populate 'accuracy' list with accuracies of classifiers trained on sparse codes \n",
      "# with different numbers of non-zero coefficients.\n",
      "# NOTE: 'sc.transform_n_nonzero_coefs = 10' sets number of non-zero elements to 10.\n",
      "    \n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.plot(n_nonzero, accuracy)\n",
      "\n",
      "print('Max accuracy: {}'.format(max(accuracy)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Eigenfaces"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we are going to do a very similar thing but with a different representation, namely, **PCA**. **`RamdomizedPCA`** class is what we need."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.decomposition import RandomizedPCA\n",
      "\n",
      "n_components = 64\n",
      "\n",
      "# Populate 'pca' with a trained instance of RamdomizedPCA."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We plot a bunch of principal components."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Visualize principal components."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This time we don't have any restriction on number of non-zero coefficients in the vector decomposition, so the codes are not sparse anymore:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Transform training data and plot decomposition coefficients."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Same pipeline as before. We train an SVM and apply it to the encoded test data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Populate 'test_score' with test accuracy of an SVM classifier.\n",
      "\n",
      "print('Test score: {}'.format(test_score))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How many components are sufficient to reach the same accuracy level?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_components = [1, 2, 4, 8, 16, 32, 64]\n",
      "accuracy = []\n",
      "\n",
      "# Try different numbers of components and populate 'accuracy' list.\n",
      "    \n",
      "plt.figure(figsize=(10, 6))\n",
      "plt.plot(n_nonzero, accuracy)\n",
      "\n",
      "print('Max accuracy: {}'.format(max(accuracy)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}